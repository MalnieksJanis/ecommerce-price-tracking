import requests
from bs4 import BeautifulSoup
import pandas as pd

# URL no kura iegūsim datus
url = "https://example.com/products"

# Iegūstam HTML datus
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

# Izvēlamies konkrētus elementus no HTML
product_names = soup.find_all('h2', class_='product-name')
prices = soup.find_all('span', class_='price')

# Saglabājam iegūtos datus sarakstā
data = {'Product': [name.text for name in product_names], 'Price': [price.text for price in prices]}
df = pd.DataFrame(data)

# Saglabājam datus CSV failā
df.to_csv('data/raw/products_data.csv', index=False)
